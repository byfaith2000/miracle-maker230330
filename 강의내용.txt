23.3.27 월

3.7~3.9버전이 안정적이다.
3.8.8이 안정적이다.
 
cd ..


▷ 처음 설치시
1. 바탕화면에 PS폴더 설치 또는 C:\Users\byfai>경로에 PS폴더 설치
내 PC에 데스크탑 없어서 위 경로에 설치함
C:\Users\byfai>cd Desktop\PS
지정된 경로를 찾을 수 없습니다.

2. CMD창에 아래 코드입력하고 엔터하면 PS폴더 안에 bigdata_lec폴더 생성됨
python -m venv bigdata_lec

3. CMD창에 아래 코드 입력하면 activate됨
bigdata_lec\Scripts\activate.bat 

4. CMD창에 아래 코드 입력하면 3개 lib. 다운로드 됨.
pip install numpy pandas matplotlib

5. 아래 싸이트에서 파이참 다운로드
https://jetbrains.com/pycharm/download/other.html
Version 2022.2
pyCharm Comunity Edition <- 이 부분에 있는 것을 받아야 함.
2022.2.4 - Windows(exe)

6. 파이참에서 New Project 만드는 법(처음 만들 때)
 - Location 제일 마지막 부분에 이름 지어주면 됨
 - Previously configured interpreter 선택, Create a main.py welcome script 체크
 - Previously configured interpreter 오른쪽 Add Interpreter 선택 > Add Local Interpreter 
 - 새로 생긴 창에서 Existing 선택 > 오른쪽 점 세개 선택 > PS폴더 안 Scripts안에 있는 python.exe 선택 후 OK
 - Create 버튼 누름

7. numpy등 제대로 깔렸는지 확인하는 법
 파이참 세팅에서 Project: bigdata_lecture 선택 > Python Interpreter 선택하면 오른쪽에 보임
 만약 안보이면 뭔가 연결이 제대로 안된 것임
 이때에는 파이참 아래 Terminal선택 > 아래 화살표 눌러 command prompt 선택
 여기에서 pip install numpy pandas matplotlib 입력 후 엔터


▷ 그 다음은 에디트 창에서
▷numpyEx1.py
import numpy as np

# array : 입력 데이터(리스트, 튜플, 배열 또는 순차형데이터)를 ndarray로 변환.
# dtype이 명시되지 않으면 자료형을 추정하고 입력데이트는 복사해서 생성
data1 = [6, 7.5, 8, 0, 1]
arr1 = np.array(data1)
print(arr1)
print(type(arr1)) #<class 'numpy.ndarray'>
print(arr1.dtype) # float64
print()
print('--------------------------------')
arr2 = np.array(data1, dtype=np.int32) # 정수 데이타로 변경됨
print(arr2)
print()

data2 = [[1,2,3,4], [5,6,7,8]]
print(data2)
print(type(data2)) # 이건 리스트가 되고
arr2 = np.array(data2)
print(type(arr2)) # 이건 n차 array가 된다.
print(arr2, '\n')
print('--------------------------------')
print(arr2.ndim) # 2차다.
print(arr2.shape) # 2행 4열이다.
print(arr2.dtype,'\n') # 정수형이다.
print('--------------------------------')
arr3 = arr2.astype(np.float32) # 실수형으로 변경
print(arr3)
print()

# arange : 내장 range함수와 유사하나 리스트 대신 ndarray반환, 일정한 간격으로 배열된 배열을 만드는 함수 array range??
arr5 = np.arange(1, 10, 2)
print(arr5)
print(np.arange(10))
print(type(arr5)) #<class 'numpy.ndarray'>
print()

#linespace : 주어진 데이터범위를 일정한 간격으로 분할해서 배열을 만든 후 튜플로 반환
arr6 = np.linspace(-3, 3, 5)
print(arr6, type(arr6))
print()

# ones : 주어진 dtype으로 배열을 생성하고 내용을 모두 1로 초기화
arr7 = np.ones([3,4])
print(arr7)
print()

# zeros : ones와 같지만 내용을 0으로 채움
arr8 = np.zeros([3,4])
print(arr8)
print()

# empty : 메모리를 할당하여 새로운 배열을 생성하지만 값을 초기화하지 않음
arr9 = np.empty([3,4])
print(arr9)
print()

arr10 = np.full([3,4], 100)
print(arr10)
print()

print(np.zeros_like(arr10))


▷numpyEx2.py
import numpy as np

# numpy 배열은 for반복문을 작성하지 않고 데이터를 일괄 처리할 수 있는 벡터화를 지원한다.

arr = np.array([[1., 2., 3.], [4., 5., 6.]])
print(arr)
print(arr * arr)
print(arr - arr)
print(1/arr)
print(arr ** 0.5) # 루터

arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])
print(arr2)
print(arr2 > arr)
print(arr2 > 4)

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>2일차<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷numpyEx1.py

import numpy as np

np.random.seed(12345)

data = np.random.normal(loc=10, scale=3, size=(4,3) )
print(data)

data2 = np.random.randint(low=0, high=10, size=10)
print(data2)

arr1 = np.arange(10)
print(arr1)
print()
np.random.shuffle(arr1)
print(arr1)
print()

arr2 = np.arange(10)
print(arr2)
arr3 = np.random.permutation(arr2)
print(arr3)


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷numpyEx2.py
import numpy as np

arr1 = np.arange(1,7).reshape(2,3)
arr2 = np.arange(7,13).reshape(2,3)
print(arr1)
print(arr2)
print()

print(np.concatenate([arr1, arr2], axis=0))
print()
print(np.concatenate([arr1, arr2], axis=1))
print()

print(np.vstack([arr1, arr2]))
print(np.hstack([arr1, arr2]))
print()

arr3 = np.arange(6)
arr4 = np.arange(6).reshape(3,2)
arr5 = np.random.randn(3,2)
print(arr3)
print()
print(arr4)
print()
print(arr5)
print()

print(np.r_[arr4, arr5])
print()

print(np.c_[arr4, arr5])
print()

print(np.c_[np.r_[arr4, arr5], arr3])


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx1.py

import numpy as np
import pandas as pd

sd1 = pd.Series([4,7,-5,3])
print(sd1)
print(type(sd1))

sd2 = pd.Series([4,7,-5,3], index=['a','b','a','c'])
print(sd2)
print()

# n디멘젼 따로 추출

print(sd2.index)
print()
print(sd2.values, type(sd2.values))

print(sd2['b'])
print()
print(sd2[['c', 'b']])
print()

sd2['b'] = 1000
print()
print(sd2)
print()

print(sd2 * 3)

print(sd2 > 3)
print()

print(sd2[sd2>3])
print()
print('----------------------------------')
print(sd2)
print(np.square((sd2)))
print()
print(np.sign(sd2))

ddata1 = {'seoul':1000, 'busan':2000, 'incheon':3000, 'daegu':4000}
print(ddata1)
print()

sd3 = pd.Series(ddata1)
print(sd3)


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx2.py

import pandas as pd

frame1 = pd.DataFrame([[2,3,4],[6,7,8]])
print(frame1)
print()

frame1 = pd.DataFrame([[2,3,4],[6,7,8]],
                      index=['one','two'],
                      columns=['first','second','third'])
print(frame1)
print()

ldata1 = [('kim','seoul',180), ('lee', 'busan', 190), ('jeung', 'suwon', 170)]
frame2 = pd.DataFrame(ldata1,
                      columns=['name', 'city', 'height'])
print(frame2)
print()

# 1: N차 딕셔너리를 데이타 프레임으로
ddata = {'city':['ohio', 'ohio', 'nevada', 'nevada', 'nevada'],
         'year':[2010, 2021, 2014, 2016, 2018],
         'pop':[1.5,1.7,2.5,2.9,3.3]}
frame3 = pd.DataFrame(ddata)
print(frame3)
print()

frame4 = pd.DataFrame(ddata,
                      columns=['year','pop','city'],
                      index=['one','two','three','four','five'])
print('-----------------')
print(frame4)
print()

print(frame4['city'])
print()
print(frame4.city)
print()
print('-----------------')
print(frame4.loc['three'])  # 행방향 가져올 때 location사용, 행렬처럼 사용할 수 있다?, 행방향은 타입이 다양하기 때문
print()
print('================================================')
print(frame4.loc['three','pop'], frame4['pop']['three'])
print()

#frame4['area'] = pd.Series([100,100,200,200,200]) # 인덱스가 안맞아서 NaN으로 나옴
#print(frame4) #NaN = Not a Number   # 판다스는 축정보와 항상 매칭이 된다 <<중요함

print('==================================================================')
#frame4['area'] = pd.Series([100,100,200,200,200], index=['one','two','three','five'])
frame4['area'] = pd.Series([100,100,200,200,200], index=frame4.index)
print(frame4)
print()

frame4.loc['six'] = pd.Series([2020, 4.1, 'texas', 700], index=frame4.columns)
print(frame4)

frame4.index.name = 'ID'
frame4.columns.name = 'ATTR'
print(frame4)


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx3.py

import pandas as pd
import numpy as np

sd1 = pd.Series([4,7,-5,3], index=list('dabc'))
print(sd1)
print()

sd2 = sd1.reindex(['a','b','c','d','e']) #e는 없으므로 NaN, NaN은 실수값으로 취급한다.
print(sd2)
print()

sd3 = pd.Series(['red','green','blue'], index=[0,2,4])
print(sd3)
print()

print(sd3.reindex(np.arange(6), method='ffill')) # frontfill, 앞에 있는 값으로 채워라, bfill, near~~

frame1 = pd.DataFrame(np.arange(9).reshape(3,3),
                      index=list('acd'),
                      columns=['one','two','three'])
print(frame1)
print()

print(frame1.reindex(['d','a','b']))
print()

print(frame1.reindex(columns=['one','three','four']))


▷pandasEx4.py
import pandas as pd
import numpy as np

sd1 = pd.Series(np.arange(5), index=list('abcde'))
print(sd1)
print()

print(sd1.drop(['c','d'])) # 원본 안바뀜
print()

sd1.drop(['c','e'], inplace=True)  # 원본 바뀜
print()
print(sd1)

frame1 = pd.DataFrame(np.arange(16),reshape(4,4),
                      index=list('abcd'),
                      columns=['one','two','three','four'])
print(frame1)
# 뭔가 안맞음(위)


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx5.py

import pandas as pd
import numpy as np

sd1 = pd.Series([4,7,2,9,1], index=list('abcde'))
print(sd1)
print()
print(sd1['b'],sd1[1])
print()

print(sd1[1:4])
print()

print(sd1['b':'e']) # e도 포함됨, 숫자는 -1

frame1 = pd.DataFrame(np.arange(16).reshape(4,4),
                      index=['ohio','colorado','utah','new york'],
                      columns=['one','two','three','four'])
print(frame1)
print()

print(frame1.iloc[1,1])  # iloc =>인티저를 기준으로 행방향?, integer location
print()
print(frame1.iloc[1:,2:])


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx6.py
import numpy as np
import pandas as pd

np.random.seed(12345)
frame1 = pd.DataFrame(np.random.randn(4,3),
                      index=['seoul', 'busan', 'incheon', 'daegu'],
                      columns=['att1', 'att2', 'att3'])
print(frame1)
print()
print('--------------------------------------')
# apply, map 많이 사용함
# 람다는 함수를 축약, x는 매개변수, : 오른쪽이 리턴값
# Dataframe일때 apply (함수, 축정보) , 해당축, 시리즈가 함수로 들어감
f1 = lambda x : x.max() - x.min()
print(frame1.apply(f1, axis=0))
print()
print(frame1.apply(f1, axis=1))
print('=======================================')
def f2(x) :
    return pd.Series([x.min(), x.max()], index=['min', 'max'])

print(frame1.apply(f2, axis=0))
print()

# Dataframe일때 apply map (함수) 하면 Dataframe 각 요소가 함수로 들어감

# 원본이 바뀌진 않음
f3 = lambda x : round(x, 2)
print(frame1.applymap(f3))
print()

# 시리즈일 때 map (함수) 사용하면 시리즈의 각값을 함수에서 사용
print(frame1['att2'].map(f3))


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx7.py
import numpy as np
import pandas as pd

frame1 = pd.DataFrame(np.arange(12).reshape(3,4), columns=list('abcd'))
frame2 = pd.DataFrame(np.arange(20).reshape(4,5), columns=list('abcde'))
print(frame2)
print()
print(frame2)
print()

print(frame1 + frame2)  # NaN + 숫자는 NaN
print()

print(frame1.add(frame2, fill_value=0))  # NaN을 0으로 한다음 계산


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx8.py
import pandas as pd
import numpy as np

sd1 = pd.Series(np.arange(4), index=list('dabc'))
print(sd1)
print()

# inplace가 True냐 False이냐에 따라 원본이 바뀌느냐 안바뀌느냐 결정됨
print(sd1.sort_index())

frame1 = pd.DataFrame(np.arange(8).reshape(2,4),
                      index=['three', 'one'],
                      columns=list('dabc'))
print(frame1)
print()
print('--------------------------------')
print(frame1.sort_index())
print()
print(frame1.sort_index(axis=1))
print()
print(frame1.sort_index(axis=1, ascending=False))
print()

sd2 = pd.Series([4,7,-3,2])
print(sd2)
print()
print(sd2.sort_values())
print()

ddata = {'a':[4,7,-3,2],
         'b':[0,1,0,1]}
frame2 = pd.DataFrame(ddata)
print(frame2)
print()

print(frame2.sort_values(by='a'))
print()
print(frame2.sort_values(by='b'))
print()
print(frame2.sort_values(by=['b','a']))  # 한번 소팅 후(b) 그 내에서 다시 소팅(a)
print()
print(frame2.sort_values(by=['b','a'], ascending=[False, True]))


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷pandasEx9.py
import numpy as np
import pandas as pd

frame = pd.DataFrame(np.random.randn(1000, 3),
                     columns=['first', 'second', 'thrid'])
print(frame)
print()

print(frame.sum())
print()
print('---------------------------------------')
print(frame.sum(axis=1))
print()

print(frame.mean())
print()

print(frame.std())
print()

print(frame.describe())
print()

frame.info()
print()

print(frame.head(10))
print()
print(frame.tail(15))

print('======================================================')
# 상관관계와 분산
frame2 = pd.DataFrame(np.random.randn(3,3),
                      columns=['ohio', 'utah', 'texas'])
print(frame2)
print()

print(frame2.ohio.corr(frame2.utah)) # 상관관계ㄱ
print(frame2.ohio.cov(frame2.utah)) # 공분산
print()

print(frame2.corr())
print()
print(frame2.cov())
print(frame2.cov())


▷pandasEx10.py
import numpy as np
import pandas as pd

sd1 = pd.Series([1, np.nan, 3.5, np.nan, 7])
print(sd1)
print()

print(sd1.notnull())
print()
print(sd1[sd1.notnull()])
print()

print(sd1.dropna())
print()

np.random.seed(1234)
frame1 = pd.DataFrame(np.random.randn(7,3),
                      columns=['one', 'two', 'three'])
frame1.iloc[:4, 1] = np.nan
frame1.iloc[:2, 2] = np.nan
print(frame1)
print()

print(frame1.fillna(0))
print()

print(frame1.fillna({'two':0.5, 'three':-1}))
print()

print(frame1.fillna(method='bfill'))

# 나머지 값들의 평균값을 넣고 싶을 때
print(frame1.mean(axis=0))
print()

print(frame1.fillna(frame1.mean(axis=0)))


▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷▷dataloadingEx1.py
import pandas as pd

frame1 = pd.read_csv('ex1.csv')
print(frame1)
print()

frame2 = pd.read_csv('ex2.csv', header=None)
print(frame2)
print()

frame3 = pd.read_csv('ex2.csv', names=['one', 'two', 'three', 'four', 'msg'])
print(frame3)

# 제일 오른쪽 내용이 인덱스인 경우
frame3 = pd.read_csv('ex2.csv', names=['one', 'two', 'three', 'four', 'msg'], index_col='msg')
print(frame3)
print()

frame3 = pd.read_csv('ex2.csv', names=['one', 'two', 'three', 'four', 'msg'], index_col=4)
print(frame3)
print()

# 2개가 인덱스인 경우
frame4 = pd.read_csv('csv_mindex.csv', index_col=['key1', 'key2'])
print(frame4)
print()

# 데이터에 주석이 있는 경우, skip할 row의 인덱스 번호 이용
frame5 = pd.read_csv('ex4.csv', skiprows=[0,2,3])
print(frame5)
print()

import numpy as np
sframe = pd.DataFrame(np.random.randn(4,3),
                      columns=['seoul', 'busan', 'incheon'])
print()



=========================================3일차==============================

pip install openpyxl  <=xlsx 파일 읽어 들일 수 있는 라이브러리

C:\Users\byfai\PS\bigdata_lec\Scripts\activate.bat

# cmd창에서 이전 디렉토리 갈 때 cd ..
# cmd창에서 \를 이용해서 디렉토리 찾아 갈 수 있음 cd (디렉토리 이름)
# Scripts에서 activate.bat 실행시키면 아래와 같이 됨

(bigdata_lec) C:\Users\byfai\PS\bigdata_lec\Scripts>

여기에서 pip install openpyxl 입력하고 엔터치면 다운로드 됨
-------------------------------------------------------------
dataMerge


dataConcatEx


combinefirstEx
# 머지, concat외 데이타를 보완해서 합치기



stack_unstackEx



# 딕셔너리를 이용해 데이터 보완
map 사용함
mapEx


# 데이터 변형 - 치환
replaceEx


# rename
renameEx


오후
cutEx
처음 잘 못 들음


# 데이터 수집과 그룹 연산
group by
groupbyEx1



aggregationEx



# groupby에도 Apply 사용할 수 있다. 

applyEx

# apply에서 사용하는 매개변수는 키워드 매개변수만 사용가능함


group_naEx


# 피벗 테이블

pivotTableEx



df_score.drop(['반','번호'], axis=1, inplace=True)
print(df_score)
print()

df_score['평균'] = df_score.mean(axis=1)
print(df_score)
print()

df_score.loc['평균'] = df_score.mean(axis=0)
print(df_score)

=============================4째날==============================



주석 처리하는 단축키는 Ctrl + / 




(오후)

barEx


산점도



cty
도시에서 1갤런당 갈 수 있는 마일수

hwy
고속도로 연비



Q
3matplotlib
ax1 = plt.gca()
ax2 = ax1.twinx()

ins1 = ax1.plot([10, 5, 2, 8, 7], 'r--', label='y1')
ax1.set_ylabel('y1')

ins2 = ax2.plot([100,200,220,190,150], 'b:', label='y2')
ax2.set_ylabel('y2')

ins = ins1 + ins2
llabels = [l.get_label() for l in ins]

plt.legend(ins, llabels, loc='best')

plt.show()

Q2 scatter
dataA = np.random.randn(100, 2)
dataA += np.array((-1, -1))

dataB = np.random.randn(100, 2)
dataB += np.array(((1, 1)))

plt.scatter(dataA[:, 0], dataA[:, 1], color='0.25')
plt.scatter(dataB[:, 0], dataB[:, 1], color='0.75', edgecolors='r')
plt.show()


Q 어떨때 scatter쓰고 어떨때 

스케트부터 복습하면 됨


연습1

Q1
랜덤에서 seed의 의미는 무엇인가요


Q3
np.random.seed(12345)
arr = np.random.randn(5,6)
print(arr)
print()

아래 코드 한번 더 설명부탁드립니다. 

print(arr[np.argsort(arr[:,0])])  #4. 첫 번째 열 값으로 모든 행으로 정렬

print(arr[:, np.argsort(arr[1])]) #5. 두네 번째 행 값으로 모든 열의 정렬

Q3 
Day3>dataloadingEx2

import pandas as pd
import numpy as np

chunker = pd.read_csv('ex6.csv', chunksize=1000)
print(chunker)
print()

tot = pd.Series([], dtype=np.float64)

for piece in chunker:
    tot = tot.add(piece['key'].value_counts(), fill_value=0)

tot = tot.sort_values(ascending=False)
print(tot[:10])


Q4
stack, unstack




Empty DataFrame
Columns: []
Index: [1, 2]

C:\Users\byfai\PycharmProjects\bigdata_lecture\Day5\dataAnalysisEx2.py:89: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.
  pdata = welfare.pivot_table(index='성별', columns='결혼유무', values='나이', aggfunc='mean')
Traceback (most recent call last):
  File "C:\Users\byfai\PycharmProjects\bigdata_lecture\Day5\dataAnalysisEx2.py", line 93, in <module>
    sns.heatmap(data=pdata, annot=True)
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\seaborn\matrix.py", line 446, in heatmap
    plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\seaborn\matrix.py", line 163, in __init__
    self._determine_cmap_params(plot_data, vmin, vmax,
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\seaborn\matrix.py", line 202, in _determine_cmap_params
    vmin = np.nanmin(calc_data)
  File "<__array_function__ internals>", line 200, in nanmin
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\numpy\lib\nanfunctions.py", line 343, in nanmin
    res = np.fmin.reduce(a, axis=axis, out=out, **kwargs)
ValueError: zero-size array to reduction operation fmin which has no identity

Process finished with exit code 1




pdata = welfare.pivot_table(index='성별', columns='결혼유무', values='나이', aggfunc='mean')
print(pdata)
print()

sns.heatmap(data=pdata, annot=True)
plt.show()





C:\Users\byfai\PycharmProjects\bigdata_lecture\Day5\dataAnalysisEx2.py:89: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.
  pdata = welfare.pivot_table(index='성별', columns='결혼 유무', values='나이', aggfunc='mean')
Traceback (most recent call last):
  File "C:\Users\byfai\PycharmProjects\bigdata_lecture\Day5\dataAnalysisEx2.py", line 93, in <module>
    sns.heatmap(data=pdata, annot=True)
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\seaborn\matrix.py", line 446, in heatmap
    plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\seaborn\matrix.py", line 163, in __init__
    self._determine_cmap_params(plot_data, vmin, vmax,
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\seaborn\matrix.py", line 202, in _determine_cmap_params
    vmin = np.nanmin(calc_data)
  File "<__array_function__ internals>", line 200, in nanmin
  File "C:\Users\byfai\PS\bigdata_lec\lib\site-packages\numpy\lib\nanfunctions.py", line 343, in nanmin
    res = np.fmin.reduce(a, axis=axis, out=out, **kwargs)
ValueError: zero-size array to reduction operation fmin which has no identity

Process finished with exit code 1

================

import seaborn as sns

# sns.countplot(data=welfare, x='결혼 유무', order=['결혼', '이혼', '무응답'], hue='종교 유무')
# plt.show()
#
# sns.countplot(data=welfare, y='결혼 유무', order=['결혼', '이혼', '무응답'], hue='종교 유무')
# plt.show()

pdata = welfare.pivot_table(index='성별', columns='결혼 유무', values='나이', aggfunc='mean')
print(pdata)
print()

sns.heatmap(data=pdata, annot=True)
plt.show()

# nwelfare = welfare.loc[:, ['직업 코드', '소득', '나이']]
# sns.pairplot(data=nwelfare)
# plt.show()

nwelfare = welfare.loc[:, ['직업코드', '소득', '나이', '결혼유무']]
sns.pair




# sns.violinplot(data=welfare, x='성별', y='나이', hue='종교유무')
# plt.show()
====================
Empty DataFrame
Columns: []
Index: [1, 2]

C:\Users\byfai\PycharmProjects\bigdata_lecture\Day5\dataAnalysisEx2.py:89: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.
  pdata = welfare.pivot_table(index='성별', columns='결혼 유무', values='나이', aggfunc='mean')
  -------------------------
  <class 'pandas.core.frame.DataFrame'>
Int64Index: 7529 entries, 0 to 7528
Data columns (total 9 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   성별      7529 non-null   int64  
 1   생일      7529 non-null   int64  
 2   결혼 유무   7529 non-null   object 
 3   종교 유무   7529 non-null   object 
 4   직업 코드   7529 non-null   float64
 5   소득      7529 non-null   float64
 6   지역구     7529 non-null   int64  
 7   나이      7529 non-null   object 
 8   직업      7529 non-null   object 
dtypes: float64(2), int64(3), object(4)
memory usage: 588.2+ KB

===================================
Q1
랜덤에서 seed의 의미는 무엇인가요


Q3
아래 코드 한번 더 설명부탁드립니다.
=========================
np.random.seed(12345)
arr = np.random.randn(5,6)
print(arr)
print()


print(arr[np.argsort(arr[:,0])])  

print(arr[:, np.argsort(arr[1])]) 

Q3 
Day3>dataloadingEx2

chunker도 한번 더 설명 부탁드려요~
===========================
import pandas as pd
import numpy as np

chunker = pd.read_csv('ex6.csv', chunksize=1000)
print(chunker)
print()

tot = pd.Series([], dtype=np.float64)

for piece in chunker:
    tot = tot.add(piece['key'].value_counts(), fill_value=0)

tot = tot.sort_values(ascending=False)
print(tot[:10])

